# Data_Cleaning
The process of finding and fixing (or eliminating) erroneous, lacking, or unnecessary data from a dataset is known as data cleaning. It is an essential stage in every data analysis or machine learning project's data preparation phase. The following are some typical actions taken during data cleaning:
1.	**Handling missing values:** Recognize and handle missing information correctly. This could entail employing algorithms that can manage missing data, deleting rows or columns that have an excessive number of missing values, or imputation—the replacement of missing values with estimated ones.
2.	**Removing duplicates:** Duplicate records should be found and eliminated from the dataset as they can distort the findings of analysis.
3.	**Handling inconsistencies:** Identify and fix problems in spelling or inconsistent naming conventions that occur during data entry or labeling.
4.	**Correcting data types:** Making sure that variables are saved in the appropriate data type—numerical variables should be recorded as numbers, categorical variables as categories, etc.
5.	**Handling outliers:** Determine whether to eliminate, modify, or retain outliers (data points that substantially differ from the rest of the data) in accordance with analysis needs and domain expertise.
6.	**Feature engineering:** To enhance the functionality of machine learning models, generate new features or extract valuable features from preexisting ones.
7.	**Handling encoding problems:** Make that text data is encoded correctly, particularly when working with several languages or character encodings.
8.	**Data validation:** Verify the quality and integrity of data by checking it against predetermined guidelines or restrictions.
9.	**Normalization and scaling:** To put numerical features on a comparable scale, normalize or scale them. This can help some machine learning algorithms work better.
10.	**Documentation:** To maintain reproducibility and transparency, document every step taken during the data cleansing process, along with the reasoning behind any decisions made.

Data cleaning is an iterative process that, depending on the intricacy of the dataset and the particular requirements of the analysis activity, frequently calls for a combination of automated tools and manual involvement.
